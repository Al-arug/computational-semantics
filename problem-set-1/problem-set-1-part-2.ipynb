{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1 - Part 2: Logic and Lambda Calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This task needs NLTK and Jupyter Notebook (IPython package).\n",
    "import nltk\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from utils import display_latex, display_translation, display_tree, display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Expression types in NLTK\n",
    "What would be the possible semantic types of each expression type in NLTK?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can translate logical and lambda expressions from string into one of the `nltk.sem.logic.Expression` types. Here is how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$x$ = `<IndividualVariableExpression x>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$P$ = `<FunctionVariableExpression P>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$rob$ = `<ConstantExpression rob>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\lambda\\ x.P(x)$ = `<LambdaExpression \\x.P(x)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\lambda\\ x.homosapien(x)$ = `<LambdaExpression \\x.homosapien(x)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$P(x)$ = `<ApplicationExpression P(x)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$P(rob)$ = `<ApplicationExpression P(rob)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$homosapien(rob)$ = `<ApplicationExpression homosapien(rob)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$(\\lambda\\ y\\ x.love(x,y))(rob)$ = `<ApplicationExpression (\\y x.love(x,y))(rob)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$(homosapien(rob)\\ \\land\\ run(rob))$ = `<AndExpression (homosapien(rob) & run(rob))>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\exists\\ x.(homosapien(x)\\ \\land\\ run(x))$ = `<ExistsExpression exists x.(homosapien(x) & run(x))>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\forall\\ x.(homosapien(x)\\ \\land\\ run(x))$ = `<AllExpression all x.(homosapien(x) & run(x))>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Note**: *Python interprets `\\` as a marker for special characters.\n",
       "To prevent this, we use `r` in `r\"strings\"` in order to force the raw interpretation of strings.*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "\n",
    "# different representations have different valid types:\n",
    "expressions = [\n",
    "    read_expr(r\"x\"),\n",
    "    read_expr(r\"P\"),\n",
    "    read_expr(r\"rob\"),\n",
    "    read_expr(r\"\\x.P(x)\"),\n",
    "    read_expr(r\"\\x.homosapien(x)\"),\n",
    "    read_expr(r\"P(x)\"),\n",
    "    read_expr(r\"P(rob)\"),\n",
    "    read_expr(r\"homosapien(rob)\"),\n",
    "    read_expr(r\"(\\y \\x.love(x, y))(rob)\"),\n",
    "    read_expr(r\"homosapien(rob) & run(rob)\"),\n",
    "    read_expr(r\"exists x.(homosapien(x) & run(x))\"),\n",
    "    read_expr(r\"all x.(homosapien(x) & run(x))\"),\n",
    "]\n",
    "\n",
    "for expr in expressions:\n",
    "    display_latex(expr, with_types=True)\n",
    "\n",
    "display(Markdown(r\"\"\"\n",
    "**Note**: *Python interprets `\\` as a marker for special characters.\n",
    "To prevent this, we use `r` in `r\"strings\"` in order to force the raw interpretation of strings.*\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some well-formed expressions do not have a valid type in a model with basic *e-type* and *t-type*.\n",
    "\n",
    "1a. Explain the problem with expression below **[2 mark]**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$(rob\\ \\land\\ marry)$ = `<AndExpression (rob & marry)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following is an *AndExpression*, where semantically *rob* and *marry* are entities (e-types).\n",
    "display_latex(read_expr(r\"rob & marry\"), with_types=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answers here*\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b. Is there any approprate translation of types from NLTK expressions to logical types with basic `e-type` and `t-type`? Explain based on the examples above. **[4 marks]** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For example:\n",
    "\n",
    "- `IndividualVariableExpression` and `FunctionVariableExpression` can be any type. There is no specific type of value for it.\n",
    "- `AndExpression` and `OrExpression` can be translated to t-type. (Because 1a)\n",
    "\n",
    "Write your answers in front of these:\n",
    "\n",
    "- `LambdaExpression`  ...\n",
    "- `ConstantExpression`  ...\n",
    "- `ExistsExpression` and `AllExpression` ...\n",
    "- `ApplicationExpression`  ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Translate verb phrases\n",
    "\n",
    "Translate the verb phrases using $\\lambda$ abstracts and verify the resulting formulae with `Expression.fromstring`.\n",
    "\n",
    "In this task, you need to translate verb phrases similar to these example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\"read by Rob\": $\\lambda\\ x.read(rob,x)$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"read a book\": $\\lambda\\ x.\\exists\\ y.(book(y)\\ \\land\\ read(x,y))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translations = {\n",
    "    \"read by Rob\": read_expr(r\"\\x.read(rob, x)\"),\n",
    "    \"read a book\": read_expr(r\"\\x. exists y. (book(y) & read(x, y))\"),\n",
    "}\n",
    "\n",
    "for text, expr in translations.items():\n",
    "    display_translation(text, expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `xxx` with valid representations in dictionary of expressions **[4 marks]**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\"be admired by no-one\": `<ConstantExpression xxx>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"catch a fish and eat it\": `<ConstantExpression xxx>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"read a book or watch a film\": `<ConstantExpression xxx>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"give every boy a dime\": `<ConstantExpression xxx>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fix the following translations:\n",
    "translations = {\n",
    "    \"be admired by no-one\":        read_expr(r\"xxx\"),\n",
    "    \"catch a fish and eat it\":     read_expr(r\"xxx\"),\n",
    "    \"read a book or watch a film\": read_expr(r\"xxx\"),\n",
    "    \"give every boy a dime\":       read_expr(r\"xxx\")\n",
    "}\n",
    "\n",
    "for text, expr in translations.items():\n",
    "    display_translation(text, expr, to_latex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Function application and $\\beta$-reduction\n",
    "In the following examples some code has been deleted and replaced with `<????>`. What has been deleted? Verify that your answer is correct. **[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$????(pip)$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$like(pip,rob)$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$????(\\lambda\\ x.play(x,scherzo))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$play(pip,scherzo)$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$????(\\lambda\\ x.play(x,etude))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\exists\\ x.(woman(x)\\ \\land\\ play(x,etude))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$????(\\lambda\\ P.\\forall\\ x.(musician(x)\\ \\to\\ P(x)))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\lambda\\ x.\\forall\\ z_{2}.(musician(z_{2})\\ \\to\\ like(x,z_{2}))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e1 = read_expr(r'????')\n",
    "e2 = read_expr(r'pip')\n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2) \n",
    "display_latex(e3.simplify())\n",
    "# with reuslt like(pip,rob).\n",
    "display_latex(read_expr(r\"like(pip,rob)\"))\n",
    "\n",
    "e1 = read_expr(r'????')\n",
    "e2 = read_expr(r'\\x.play(x,scherzo)') \n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2)\n",
    "display_latex(e3.simplify())\n",
    "# with result play(pip,scherzo).\n",
    "display_latex(read_expr(r\"play(pip,scherzo)\"))\n",
    "\n",
    "e1 = read_expr(r'????')\n",
    "e2 = read_expr(r'\\x.play(x,etude)') \n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2) \n",
    "display_latex(e3.simplify())\n",
    "# with result exists x.(woman(x) & play(x,etude)).\n",
    "display_latex(read_expr(r\"exists x.(woman(x) & play(x,etude))\"))\n",
    "\n",
    "e1 = read_expr(r'????')\n",
    "e2 = read_expr(r'\\P.all x. (musician(x) -> P(x))') \n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2) \n",
    "display_latex(e3.simplify())\n",
    "# with result \\x.all z2.(musician(z2) -> like(x,z2)).\n",
    "display_latex(read_expr(r\"\\x.all z2.(musician(z2) -> like(x,z2))\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extend FCFG Grammar\n",
    "Extend the grammar simple_sem.fcfg that comes with NLTK `(~/nltk_data/grammars/book_grammars/)` so that it will cover the following sentences. The grammar is included in the code below as a string.\n",
    "\n",
    "- no man gives a bone to a dog **[4 marks]**\n",
    "- a boy and a girl chased every dog **[2 marks]**\n",
    "- every dog chased a boy and a girl **[2 marks]**\n",
    "- a brown cat chases a white dog **[4 marks]**\n",
    "\n",
    "The last example includes adjectives. Several different kinds of adjectives are discussed in the literature. In this example we have an intersective adjective. The denotiation we might want for brown cat is a set of individuals having a brown property and cat property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcfg_string_orginal = r\"\"\"\n",
    "% start S\n",
    "############################\n",
    "# Grammar Rules\n",
    "#############################\n",
    "\n",
    "S[SEM = <?subj(?vp)>] -> NP[NUM=?n,SEM=?subj] VP[NUM=?n,SEM=?vp]\n",
    "\n",
    "NP[NUM=?n,SEM=<?det(?nom)> ] -> Det[NUM=?n,SEM=?det]  Nom[NUM=?n,SEM=?nom]\n",
    "NP[LOC=?l,NUM=?n,SEM=?np] -> PropN[LOC=?l,NUM=?n,SEM=?np]\n",
    "\n",
    "Nom[NUM=?n,SEM=?nom] -> N[NUM=?n,SEM=?nom]\n",
    "\n",
    "VP[NUM=?n,SEM=?v] -> IV[NUM=?n,SEM=?v]\n",
    "VP[NUM=?n,SEM=<?v(?obj)>] -> TV[NUM=?n,SEM=?v] NP[SEM=?obj]\n",
    "VP[NUM=?n,SEM=<?v(?obj,?pp)>] -> DTV[NUM=?n,SEM=?v] NP[SEM=?obj] PP[+TO,SEM=?pp]\n",
    "\n",
    "PP[+TO, SEM=?np] -> P[+TO] NP[SEM=?np]\n",
    "\n",
    "#############################\n",
    "# Lexical Rules\n",
    "#############################\n",
    "\n",
    "PropN[-LOC,NUM=sg,SEM=<\\P.P(angus)>] -> 'Angus'\n",
    "PropN[-LOC,NUM=sg,SEM=<\\P.P(cyril)>] -> 'Cyril'\n",
    "PropN[-LOC,NUM=sg,SEM=<\\P.P(irene)>] -> 'Irene'\n",
    " \n",
    "Det[NUM=sg,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'every'\n",
    "Det[NUM=pl,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'all'\n",
    "Det[SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'some'\n",
    "Det[NUM=sg,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'a'\n",
    "Det[NUM=sg,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'an'\n",
    "\n",
    "N[NUM=sg,SEM=<\\x.man(x)>] -> 'man'\n",
    "N[NUM=sg,SEM=<\\x.girl(x)>] -> 'girl'\n",
    "N[NUM=sg,SEM=<\\x.boy(x)>] -> 'boy'\n",
    "N[NUM=sg,SEM=<\\x.bone(x)>] -> 'bone'\n",
    "N[NUM=sg,SEM=<\\x.ankle(x)>] -> 'ankle'\n",
    "N[NUM=sg,SEM=<\\x.dog(x)>] -> 'dog'\n",
    "N[NUM=pl,SEM=<\\x.dog(x)>] -> 'dogs'\n",
    "\n",
    "IV[NUM=sg,SEM=<\\x.bark(x)>,TNS=pres] -> 'barks'\n",
    "IV[NUM=pl,SEM=<\\x.bark(x)>,TNS=pres] -> 'bark'\n",
    "IV[NUM=sg,SEM=<\\x.walk(x)>,TNS=pres] -> 'walks'\n",
    "IV[NUM=pl,SEM=<\\x.walk(x)>,TNS=pres] -> 'walk'\n",
    "TV[NUM=sg,SEM=<\\X x.X(\\ y.chase(x,y))>,TNS=pres] -> 'chases'\n",
    "TV[NUM=pl,SEM=<\\X x.X(\\ y.chase(x,y))>,TNS=pres] -> 'chase'\n",
    "TV[NUM=sg,SEM=<\\X x.X(\\ y.see(x,y))>,TNS=pres] -> 'sees'\n",
    "TV[NUM=pl,SEM=<\\X x.X(\\ y.see(x,y))>,TNS=pres] -> 'see'\n",
    "TV[NUM=sg,SEM=<\\X x.X(\\ y.bite(x,y))>,TNS=pres] -> 'bites'\n",
    "TV[NUM=pl,SEM=<\\X x.X(\\ y.bite(x,y))>,TNS=pres] -> 'bite'\n",
    "DTV[NUM=sg,SEM=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>,TNS=pres] -> 'gives'\n",
    "DTV[NUM=pl,SEM=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>,TNS=pres] -> 'give'\n",
    "\n",
    "P[+to] -> 'to'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcfg_string = fcfg_string_orginal + r\"\"\"\n",
    "## Your answers here\n",
    "# Det[???] -> ???\n",
    "# TV[???] -> ???\n",
    "# TV[???] -> ???\n",
    "# CONJ -> ???\n",
    "# NP[???] -> NP[???] CONJ NP[???]\n",
    "# N[???] -> ???\n",
    "# ADJ[???] -> ???\n",
    "# NP[???] -> Det[???] ADJ[???] Nom[???]\n",
    "\"\"\"\n",
    "\n",
    "# Load `fcfg_string` as a feature grammar:\n",
    "syntax = FeatureGrammar.fromstring(fcfg_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below without errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: \"'no'\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a4c523532b04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m'a brown cat chases a white dog'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ]\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyntax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msynrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemrep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/sem/util.py\u001b[0m in \u001b[0;36minterpret_sents\u001b[0;34m(inputs, grammar, semkey, trace)\u001b[0m\n\u001b[1;32m     86\u001b[0m     return [\n\u001b[1;32m     87\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_semrep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msyn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msyntrees\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msyntrees\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparse_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     ]\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/sem/util.py\u001b[0m in \u001b[0;36mparse_sents\u001b[0;34m(inputs, grammar, trace)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# use a tokenizer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0msyntrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mparses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyntrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/parse/chart.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokens, tree_class)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchart_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/parse/chart.py\u001b[0m in \u001b[0;36mchart_parse\u001b[0;34m(self, tokens, trace)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_coverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chart_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[0mgrammar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mcheck_coverage\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             raise ValueError(\n\u001b[0;32m--> 684\u001b[0;31m                 \u001b[0;34m\"Grammar does not cover some of the \"\u001b[0m \u001b[0;34m\"input words: %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m             )\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'no'\"."
     ]
    }
   ],
   "source": [
    "# remove sentences if you couldn't find answer for them\n",
    "sentences = [\n",
    "    'no man gives a bone to a dog',\n",
    "    'a boy and a girl chased every dog',\n",
    "    'every dog chased a boy and a girl',\n",
    "    'a brown cat chases a white dog',\n",
    "]\n",
    "for results in nltk.interpret_sents(sentences, syntax):\n",
    "    for (synrep, semrep) in results:\n",
    "        display(Markdown('----'))\n",
    "        display_latex(semrep) # prints the SEM feature of a tree\n",
    "        display_tree(synrep) # show the parse tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with iPython which is also running behind Jupyter notebooks and you are changing grammars and want to rerun a new version without restarting you may find `nltk.data.clear_cache()` useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ambiguity in quantifiers\n",
    "\n",
    "Explain ambiguity of these sentences. \n",
    "\n",
    "Use parse the following sentences:\n",
    "\n",
    "- every dog bites a bone\n",
    "- a man gives a bone to every dog\n",
    "- every dog chased a boy and a girl *(optional)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax = FeatureGrammar.fromstring(fcfg_string_orginal)\n",
    "sentences = [\n",
    "    'all dogs bite a bone',\n",
    "    'a man gives a bone to every dog',\n",
    "    #'every dog chased a boy and a girl',\n",
    "]\n",
    "sents_reps = []\n",
    "for results in nltk.interpret_sents(sentences, syntax):\n",
    "    for (synrep, semrep) in results:\n",
    "        display(Markdown('----'))\n",
    "        display_latex(semrep) # prints the SEM feature of a tree\n",
    "        display_tree(synrep) # show the parse tree\n",
    "        sents_reps.append(semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5a. Write at least one alternative logical representation for each sentence. **[2+1 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers here\n",
    "\n",
    "# all dogs bite a bone\n",
    "semrep = read_expr(r\"???\")\n",
    "display_latex(semrep)\n",
    "\n",
    "# a man gives a bone to every dog\n",
    "semrep = read_expr(r\"???\")\n",
    "display_latex(semrep)\n",
    "\n",
    "# every dog chased a boy and a girl\n",
    "semrep = read_expr(r\"???\")\n",
    "display_latex(semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5b. Are they semantic or syntactic ambiguities? **[2+1 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model and valuation\n",
    "\n",
    "Find a model for statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original readings of two sentences in question 5 are false in the model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom = set([\n",
    "    'd1', 'd2', 'd3',\n",
    "    'b1', 'b2',\n",
    "    'g1', 'g2',\n",
    "    'm1', 'm2',\n",
    "    'bn1', 'bn2'\n",
    "])\n",
    "val = nltk.Valuation.fromstring(\"\"\"\n",
    "dog   => {d1, d2, d3}\n",
    "boy   => {b1, b2}\n",
    "girl  => {g1, g2}\n",
    "man   => {m1, m2}\n",
    "bone  => {bn1, bn2}\n",
    "bite  => {(d1, bn1)}\n",
    "give  => {(m1, bn1, d1)}\n",
    "\"\"\")\n",
    "\n",
    "g = nltk.Assignment(dom)\n",
    "m = nltk.Model(dom, val)\n",
    "\n",
    "for semrep in sents_reps:\n",
    "    print(m.evaluate(str(semrep), g))\n",
    "    display_latex(semrep)\n",
    "    display(Markdown('----'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6a. Change the sets of `bite` and `give` in the model, so two sentences in question 5 become true. **[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers here\n",
    "# copy from the model above then modify bite and give.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6b. *(optional)* Write a mobification of `bite` and `give` which the alternative reading in 5a become true. (If you already have that in 6a write a model that the alternative reading in 5a is false but the original reading is true)   **[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6c. *(optional)* extend the world model with `chase`, repeat 6a and 6b for \"every dog chased a boy and a girl\". **[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting your answers\n",
    "\n",
    "There are **34 marks** and **10 optional marks** on this problem-set. In order to obtain a G you need at least **17 marks**. In order to obtain a VG you need at least **26 marks**.\n",
    "\n",
    "The lab is meant as an exploration and learning exercise. If you get stuck, please write your questions to the discussion topic for this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
